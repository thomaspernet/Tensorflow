{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is TensorFlow?\n",
    "\n",
    "Currently, the most famous deep learning library in the world is\n",
    "Google's TensorFlow. Google product uses machine learning in all of its\n",
    "products to improve the search engine, translation, image captioning or\n",
    "recommendations.\n",
    "\n",
    "To give a concrete example, Google users can experience a faster and\n",
    "more refined the search with AI. If the user types a keyword a the\n",
    "search bar, Google provides a recommendation about what could be the\n",
    "next word.\n",
    "\n",
    "\n",
    "![](https://media.giphy.com/media/57Uh5v2Uz40hoHssR9/giphy.gif)\n",
    "\n",
    "\n",
    "Google wants to use machine learning to take advantage of their massive\n",
    "datasets to give users the best experience. Three different groups use\n",
    "machine learning:\n",
    "\n",
    "-   Researchers\n",
    "\n",
    "-   Data scientists\n",
    "\n",
    "-   Programmers.\n",
    "\n",
    "They can all use the same toolset to collaborate with each other and\n",
    "improve their efficiency.\n",
    "\n",
    "Google does not just have any data; they have the world's most massive\n",
    "computer, so TensorFlow was built to scale. TensorFlow is a library\n",
    "developed by the Google Brain Team to accelerate machine learning and\n",
    "deep neural network research.\n",
    "\n",
    "It was built to run on multiple CPUs or GPUs and even mobile operating\n",
    "systems, and it has several wrappers in several languages like Python,\n",
    "C++ or Java.\n",
    "\n",
    "## History of TensorFlow\n",
    "\n",
    "A couple of years ago, deep learning started to outperform all other\n",
    "machine learning algorithms when giving a massive amount of data. Google\n",
    "saw it could use these deep neural networks to improve its services:\n",
    "\n",
    "-   Gmail\n",
    "\n",
    "-   Photo\n",
    "\n",
    "-   Google search engine\n",
    "\n",
    "They build a framework called **Tensorflow** to let researchers and\n",
    "developers work together on an AI model. Once developed and scaled, it\n",
    "allows lots of people to use it.\n",
    "\n",
    "It was first made public in late 2015, while the first stable version\n",
    "appeared in 2017. It is open source under Apache Open Source license.\n",
    "You can use it, modify it and redistribute the modified version for a\n",
    "fee without paying anything to Google.\n",
    "\n",
    "## TensorFlow Architecture\n",
    "\n",
    "Tensorflow architecture works in three parts:\n",
    "\n",
    "-   Preprocessing the data\n",
    "\n",
    "-   Build the model\n",
    "\n",
    "-   Train and estimate the model\n",
    "\n",
    "It is called Tensorflow because it takes input as a multi-dimensional\n",
    "array, also known as **tensors**. You can construct a sort of\n",
    "**flowchart** of operations (called a Graph) that you want to perform on\n",
    "that input. The input goes in at one end, and then it flows through this\n",
    "system of multiple operations and comes out the other end as output.\n",
    "\n",
    "This is why it is called TensorFlow because the tensor goes in it flows\n",
    "through a list of operations, and then it comes out the other side.\n",
    "\n",
    "## Where can Tensorflow run?\n",
    "\n",
    "TensorFlow can hardware, and software requirements can be classified\n",
    "into\n",
    "\n",
    "Development Phase: This is when you train the mode. Training is usually\n",
    "done on your Desktop or laptop.\n",
    "\n",
    "Run Phase or Inference Phase: Once training is done Tensorflow can be\n",
    "run on many different platforms. You can run it on\n",
    "\n",
    "-   Desktop running Windows, macOS or Linux\n",
    "\n",
    "-   Cloud as a web service\n",
    "\n",
    "-   Mobile devices like iOS and Android\n",
    "\n",
    "You can train it on multiple machines then you can run it on a different\n",
    "machine, once you have the trained model.\n",
    "\n",
    "The model can be trained and used on GPUs as well as CPUs. GPUs were\n",
    "initially designed for video games. In late 2010, Stanford researchers\n",
    "found that GPU was also very good at matrix operations and algebra so\n",
    "that it makes them very fast for doing these kinds of calculations. Deep\n",
    "learning relies on a lot of matrix multiplication. TensorFlow is very\n",
    "fast at computing the matrix multiplication because it is written in\n",
    "C++. Although it is implemented in C++, TensorFlow can be accessed and\n",
    "controlled by other languages mainly, Python.\n",
    "\n",
    "Finally, a significant feature of TensorFlow is the TensorBoard. The\n",
    "TensorBoard enables to monitor graphically and visually what TensorFlow\n",
    "is doing.\n",
    "\n",
    "### Components of TensorFlow\n",
    "\n",
    "### Tensor\n",
    "\n",
    "Tensorflowâ€™s name is directly derived from its core framework:\n",
    "**Tensor**. In Tensorflow, all the computations involve tensors. A\n",
    "tensor is a **vector** or **matrix** of n-dimensions that represents all\n",
    "types of data. All values in a tensor hold identical data type with a\n",
    "known (or partially known) **shape**. The shape of the data is the\n",
    "dimensionality of the matrix or array.\n",
    "\n",
    "A tensor can be originated from the input data or the result of a\n",
    "computation. In TensorFlow, all the operations are conducted inside a\n",
    "**graph**. The graph is a set of computation that takes place\n",
    "successively. Each operation is called an **op node** and are connected\n",
    "to each other.\n",
    "\n",
    "The graph outlines the ops and connections between the nodes. However,\n",
    "it does not display the values. The edge of the nodes is the tensor,\n",
    "i.e., a way to populate the operation with data.\n",
    "\n",
    "### Graphs\n",
    "\n",
    "TensorFlow makes use of a graph framework. The graph gathers and\n",
    "describes all the series computations done during the training. The\n",
    "graph has lots of advantages:\n",
    "\n",
    "-   It was done to run on multiple CPUs or GPUs and even mobile\n",
    "    operating system\n",
    "\n",
    "-   The portability of the graph allows to preserve the computations for\n",
    "    immediate or later use. The graph can be saved to be executed in the\n",
    "    future.\n",
    "\n",
    "-   All the computations in the graph are done by connecting tensors\n",
    "    together\n",
    "\n",
    "-   A tensor has a node and an edge. The node carries the\n",
    "    mathematical operation and produces an endpoints outputs. The\n",
    "    edges the edges explain the input/output relationships between\n",
    "    nodes.\n",
    "\n",
    "\n",
    "### Why is TensorFlow popular?\n",
    "\n",
    "TensorFlow is the best library of all because it is built to be\n",
    "accessible for everyone. Tensorflow library incorporates different API\n",
    "to built at scale deep learning architecture like CNN or RNN. TensorFlow\n",
    "is based on graph computation; it allows the developer to visualize the\n",
    "construction of the neural network with Tensorboad. This tool is helpful\n",
    "to debug the program. Finally, Tensorflow is built to be deployed at\n",
    "scale. It runs on CPU and GPU.\n",
    "\n",
    "Tensorflow attracts the largest popularity on GitHub compare to the\n",
    "other deep learning framework.\n",
    "\n",
    "### List of Prominent Algorithms supported by TensorFlow\n",
    "\n",
    "Currently, TensorFlow 1.10 has a built-in API for:\n",
    "\n",
    "-   Linear regression: `tf.estimator.LinearRegressor`\n",
    "\n",
    "-   Classification:`tf.estimator.LinearClassifier`\n",
    "\n",
    "-   Deep learning classification: `tf.estimator.DNNClassifier`\n",
    "\n",
    "-   Deep learning wipe and deep:\n",
    "    `tf.estimator.DNNLinearCombinedClassifier`\n",
    "\n",
    "-   Booster tree regression: `tf.estimator.BoostedTreesRegressor`\n",
    "\n",
    "-   Boosted tree classification: `tf.estimator.BoostedTreesClassifier`\n",
    "\n",
    "## Basic Workflow to create a program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Thomas/anaconda3/envs/hello-tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first two line of code, we have imported `tensorflow` as `tf`.\n",
    "With Python, it is a common practice to use a short name for a library.\n",
    "The advantage is to avoid to type the full name of the library when we\n",
    "need to use it. For instance, we can import tensorflow as tf, and call\n",
    "tf when we want to use a tensorflow function\n",
    "\n",
    "Let 's practice the elementary workflow of Tensorflow with a simple\n",
    "example. Let 's create a computational graph that multiplies two numbers\n",
    "together.\n",
    "\n",
    "During the example, we will multiply `X_1` and `X_2` together. Tensorflow\n",
    "will create a node to connect the operation. In our example, it is\n",
    "called multiply. When the graph is determined, Tensorflow computational\n",
    "engines will multiply together `X_1` and `X_2`.\n",
    "\n",
    "![](https://github.com/thomaspernet/Tensorflow/blob/master/tensorflow/6_tf_v14_files/image002.png)\n",
    "\n",
    "Finally, we will run a TensorFlow session that will run the\n",
    "computational graph with the values of `X_1` and `X_2` and print the\n",
    "result of the multiplication.\n",
    "\n",
    "Let's define the `X_1` and `X_2` input nodes. When we create a node in\n",
    "Tensorflow, we have to choose what kind of node to create. The `X_1` and\n",
    "`X_2` nodes will be a placeholder node. The placeholder assigns a new\n",
    "value each time we make a calculation. We will create them as a TF dot\n",
    "placeholder node.\n",
    "\n",
    "**Step 1**: Define the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = tf.placeholder(tf.float32, name = \"X_1\")\n",
    "X_2 = tf.placeholder(tf.float32, name = \"X_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create a placeholder node, we have to pass in the data type will\n",
    "be adding numbers here so we can use a floating-point data type, let's\n",
    "use `tf.float32`. We also need to give this node a name. This name\n",
    "will show up when we look at the graphical visualizations of our model.\n",
    "Let's name this node `X_1` by passing in a parameter called `name` with\n",
    "a value of `X_1` and now let's define `X_2` the same way, `X_2`.\n",
    "\n",
    "**Step 2**: Define the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply = tf.multiply(X_1, X_2, name =\n",
    "\"multiply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the node that does the multiplication operation. In\n",
    "Tensorflow we can do that by creating a `tf.multiply` node.\n",
    "\n",
    "We will pass in the `X_1` and `X_2` nodes to the multiplication node. It\n",
    "tells tensorflow to link those nodes in the computational graph, so we\n",
    "are asking it to pull the values from `x` and `y` and multiply the result.\n",
    "Let's also give the multiplication node the name `multiply`. It is the\n",
    "entire definition for our simple computational graph.\n",
    "\n",
    "**Step 3**: Execute the operation\n",
    "\n",
    "To execute operations in the graph, we have to create a session. In\n",
    "Tensorflow, it is done by `tf.Session()`. Now that we have a `session`\n",
    "we can ask the session to run operations on our computational graph by\n",
    "calling `session`. To run the computation, we need to use `run`.\n",
    "\n",
    "When the addition operation runs, it is going to see that it needs to\n",
    "grab the values of the `X_1` and `X_2` nodes, so we also need to feed in\n",
    "values for `X_1` and `X_2`. We can do that by supplying a parameter\n",
    "called `feed_dict`. We pass the value `1,2,3` for `X_1` and `4,5,6` for\n",
    "`X_2`.\n",
    "\n",
    "We print the results with `print(result)`. We should see 4, 10 and 18\n",
    "for 1x4, 2x5 and 3x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4. 10. 18.]\n"
     ]
    }
   ],
   "source": [
    "X_1 = tf.placeholder(tf.float32, name = \"X_1\")\n",
    "X_2 = tf.placeholder(tf.float32, name = \"X_2\")\n",
    "\n",
    "multiply = tf.multiply(X_1, X_2, name = \"multiply\")\n",
    "\n",
    "with tf.Session() as session:\n",
    "    result = session.run(multiply, feed_dict={X_1:[1,2,3], X_2:[4,5,6]})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options to Load Data into TensorFlow\n",
    "\n",
    "The first step before training a machine learning algorithm is to load the data. There is two commons way to load data:\n",
    "\n",
    "1. Load data into memory: It is the simplest method. You load all your data into memory as a single array. You can write a Python code. This lines of code are unrelated to Tensorflow. \n",
    "\n",
    "2. Tensorflow data pipeline. Tensorflow has built-in API that helps you to load the data, perform the operation and feed the machine learning algorithm easily. This method works very well especially when you have a large dataset. For instance, image records are known to be enormous and do not fit into memory. The data pipeline manages the memory by itself\n",
    "\n",
    "### What solution to use?\n",
    "\n",
    "**Load data in memory**\n",
    "\n",
    "If your dataset is not too big, i.e., less than 10 gigabytes, you can use the first method. The data can fit into the memory. You can use a famous library called Pandas to import CSV files. You will learn more about pandas in the next tutorial.\n",
    "\n",
    "**Load data with Tensorflow pipeline**\n",
    "\n",
    "The second method works best if you have a large dataset. For instance, if you have a dataset of 50 gigabytes, and your computer has only 16 gigabytes of memory then the machine will crash. \n",
    "\n",
    "In this situation, you need to build a Tensorflow pipeline. The pipeline will load the data in batch, or small chunk. Each batch will be pushed to the pipeline and be ready for the training. Building a pipeline is an excellent solution because it allows you to use parallel computing. It means Tensorflow will train the model across multiple CPUs. It fosters the computation and permits for training powerful neural network. \n",
    "\n",
    "You will see in the next tutorials on how to build a significant pipeline to feed your neural network.\n",
    "\n",
    "In a nutshell, if you have a small dataset, you can load the data in memory with Pandas library. \n",
    "\n",
    "If you have a large dataset and you want to make use of multiple CPUs, then you will be more comfortable to work with Tensorflow pipeline.  \n",
    "\n",
    "In the example before, we manually add three values for `X_1` and `X_2`.\n",
    "Now we will see how to load data to Tensorflow.\n",
    "\n",
    "**Step **1: Create the data\n",
    "\n",
    "First of all, let's use numpy library to generate two random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99529608 0.3372634 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_input = np.random.sample((1,2))\n",
    "print(x_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Create the placeholder\n",
    "\n",
    "Like in the previous example, we create a placeholder with the name `X`.\n",
    "We need to specify the shape of the tensor explicitly. In case, we will\n",
    "load an array with only two values. We can write the shape as\n",
    "`shape``=[``1,2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a placeholder\n",
    "x = tf.placeholder(tf.float32, shape=[1,2], name = 'X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Define the dataset method\n",
    "\n",
    "next, we need to define the `Dataset` where we can populate the value of\n",
    "the placeholder `x`. We need to use the method\n",
    "`tf.data.Dataset.from_tensor_slices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Create the pipeline**\n",
    "\n",
    "In step four, we need to initialize the pipeline where the data will\n",
    "flow. We need to create an iterator with `make_initializable_iterator`.\n",
    "We name it `iterator`. Then we need to call this iterator to feed the\n",
    "next batch of data, `get_next`. We name this step `get_next`. Note that\n",
    "in our example, there is only one batch of data with only two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator() \n",
    "get_next = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Execute the operation\n",
    "\n",
    "The last step is similar to the previous example. We initiate a\n",
    "`session`, and we run the operation `iterator`. We feed the `feed_dict`\n",
    "with the value generated by numpy. These two value will populate the\n",
    "placeholder `x`. Then we run `get_next` to print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99529606 0.3372634 ]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # feed the placeholder with data\n",
    "    sess.run(iterator.initializer, feed_dict={ x: x_input }) \n",
    "    print(sess.run(get_next)) # output [ 0.52374458  0.71968478]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "TensorFlow is the most famous deep learning library these recent years.\n",
    "A practitioner using TensorFlow can build any deep learning structure,\n",
    "like CNN, RNN or simple artificial neural network.\n",
    "\n",
    "TensorFlow is mostly used by academics, startups, and large companies.\n",
    "Google uses TensorFlow in almost all Google daily products including\n",
    "Gmail, Photo and Google Search Engine.\n",
    "\n",
    "Google Brain team's developed TensorFlow to fill the gap between\n",
    "researchers and products developers. In 2015, they made TensorFlow\n",
    "public; it is rapidly growing in popularity. Nowadays, TensorFlow is the\n",
    "deep learning library with the most repositories on GitHub.\n",
    "\n",
    "Practitioners use Tensorflow because it is easy to deploy at scale. It\n",
    "is built to work in the cloud or on mobile devices like iOs and Android.\n",
    "\n",
    "Tensorflow works in a session. Each session is defined by a graph with\n",
    "different computations. A simple example can be to multiply to number.\n",
    "In Tensorflow, three steps are required:\n",
    "\n",
    "1.  Define the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = tf.placeholder(tf.float32, name = \"X_1\")\n",
    "X_2 = tf.placeholder(tf.float32, name = \"X_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Define the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply = tf.multiply(X_1, X_2, name = \"multiply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Execute the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4. 10. 18.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    result = session.run(multiply, feed_dict={X_1:[1,2,3], X_2:[4,5,6]})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common practice in Tensorflow is to create a pipeline to load the\n",
    "data. If you follow these five steps, you'll be able to load data to\n",
    "TensorFLow\n",
    "\n",
    "1.  Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26217124 0.52216952]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_input = np.random.sample((1,2))\n",
    "print(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Create the placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[1,2], name = 'X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Define the dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "get_next = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  Execute the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26217124 0.52216953]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "   sess.run(iterator.initializer, feed_dict={ x: x_input })\n",
    "   print(sess.run(get_next)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
