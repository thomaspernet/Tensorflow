{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow  \n",
    "\n",
    "## Linear regression\n",
    "\n",
    "In this tutorial, you will learn basic principles of linear regression\n",
    "and machine learning in general.\n",
    "\n",
    "TensorFlow provides tools to have full control of the computations. This\n",
    "is done with the low-level API. On top of that, TensorFlow is equipped\n",
    "with a vast array of APIs to perform many machine learning algorithms.\n",
    "This is the high-level API. TensorFlow calls them estimators\n",
    "\n",
    "-   Low-level API: Build the architecture, optimization of the model\n",
    "    from scratch. It is complicated for a beginner\n",
    "\n",
    "-   High-level API: Define the algorithm. It is easer-friendly.\n",
    "    TensorFlow provides a toolbox calls **estimator** to construct,\n",
    "    train, evaluate and make a prediction.\n",
    "\n",
    "In this tutorial, you will use the **estimators only**. The computations\n",
    "are faster and are easier to implement. The first part of the tutorial\n",
    "explains how to use the gradient descent optimizer to train a linear\n",
    "regression. In a second part, you will use the Boston dataset to predict\n",
    "the price of a house using TensorFlow estimator.\n",
    "\n",
    "## How to train a linear regression model\n",
    "\n",
    "Before we begin to train the model, let’s have look at what is a linear\n",
    "regression.\n",
    "\n",
    "Imagine you have two variables, $x$ and $y$ and your task is to predict\n",
    "the value of $y$ knowing the value of $x$. If you plot the data, you can\n",
    "see a positive relationship between your independent variable, $x$ and\n",
    "your dependent variable $y$.\n",
    "\n",
    "<img src=\"image/image58.png\" >\n",
    "\n",
    "You may observe, if $x = 1$, $y$ will roughly be equal to 6 and if\n",
    "$x = 2$, $y$ will be around 8.5.\n",
    "\n",
    "This is not a very accurate method and prone to error, especially with a\n",
    "dataset with hundreds of thousands of points.\n",
    "\n",
    "A linear regression is evaluated with an equation. The variable $y$ is\n",
    "explained by one or many covariates. In your example, there is only one\n",
    "dependent variable. If you have to write this equation, it will be:\n",
    "\n",
    "$$y = \\beta + \\alpha X + \\epsilon$$\n",
    "\n",
    "With:\n",
    "\n",
    "-   $\\beta$ is the bias. i.e. if $x = 0$, $y = \\beta$\n",
    "\n",
    "-   $\\alpha$ is the weight associated to $x$\n",
    "\n",
    "-   $\\epsilon$ is the residual or the error of the model. It includes\n",
    "    what the model cannot learn from the data\n",
    "\n",
    "Imagine you fit the model and you find the following solution for:\n",
    "\n",
    "-   $\\beta = 3.8$\n",
    "\n",
    "-   $\\alpha = 2.78$\n",
    "\n",
    "You can substitute those numbers in the equation and it becomes:\n",
    "\n",
    "$$y = 3.8 + 2.78x$$\n",
    "\n",
    "You have now a better way to find the values for $y$. That is, you can\n",
    "replace $x$ with any value you want to predict $y$. In the image below,\n",
    "we have replace $x$ in the equation with all the values in the dataset\n",
    "and plot the result.\n",
    "\n",
    "<img src=\"image/image59.png\" >\n",
    "\n",
    "The red line represents the fitted value, that is the values of $y$ for\n",
    "each value of $x$. You don’t need to see the value of $x$ to predict\n",
    "$y$, for each $x$ there is an$y$ which belongs to the red line. You can\n",
    "also predict for values of $x$ higher than 2!\n",
    "\n",
    "If you want to extend the linear regression to more covariates, you can\n",
    "by adding more variables to the model. The difference between\n",
    "traditional analysis and linear regression is the linear regression\n",
    "looks at how $y$ will react for each variable $X$ taken independently.\n",
    "\n",
    "Let’s see an example. Imagine you want to predict the sales of an ice\n",
    "cream shop. The dataset contains different information such as the\n",
    "weather (i.e rainy, sunny, cloudy), customer informations (i.e salary,\n",
    "gender, marital status).\n",
    "\n",
    "Traditional analysis will try to predict the sale by let’s say computing\n",
    "the average for each variable and try to estimate the sale for different\n",
    "scenarios. It will lead to poor predictions and restrict the analysis to\n",
    "the chosen scenario.\n",
    "\n",
    "If you use linear regression, you can write this equation:\n",
    "\n",
    "$$Sales\\  = \\beta + \\alpha_{1}weather + \\alpha_{2}salary + \\alpha_{3}\\text{gende}r + \\alpha_{4}\\text{marita}l + \\epsilon$$\n",
    "\n",
    "The algorithm will find the best solution for the weights; it means it\n",
    "will try to minimize the cost (the difference between the fitted line\n",
    "and the data points).\n",
    "\n",
    "**How the algorithm works**\n",
    "\n",
    "<img src=\"image/image59_1.png\" >\n",
    "\n",
    "The algorithm will choose a random number for each $\\beta$ and $\\alpha$\n",
    "and replace the value of $x$ to get the predicted value of $y$. If the\n",
    "dataset has 100 observations, the algorithm computes 100 predicted\n",
    "values.\n",
    "\n",
    "We can compute the error, noted $\\epsilon,\\ $ of the model, which is the\n",
    "difference between the predicted value and the real value. A positive\n",
    "error means the model underestimates the prediction of y, and a negative\n",
    "error means the model overestimates the prediction of y.\n",
    "\n",
    "$$\\epsilon = y - ypred$$\n",
    "\n",
    "Your goal is to minimize the square of the error. The algorithm computes\n",
    "the mean of the square error. This step is called minimization of the\n",
    "error. For linear regression is the **Mean Square Error**, also called\n",
    "MSE. Mathematically, it is:\n",
    "\n",
    "$$MSE(X) = \\frac{1}{m}\\sum_{i = 1}^{m}(\\theta^{T}x^{i} - y^{i})^{2}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "-   $\\theta^{T}\\ $is the weights so $\\theta^{T}x^{i}\\ $refers to the\n",
    "    predicted value\n",
    "\n",
    "-   y is the real values\n",
    "\n",
    "-   m is the number of observations\n",
    "\n",
    "Note that $\\theta^{T}$ means it uses the transpose of the matrices. The\n",
    "$\\frac{1}{m}\\sum$ is the mathematical notation of the mean.\n",
    "\n",
    "The goal is to find the best $\\theta$ that minimize the MSE\n",
    "\n",
    "If the average error is large, it means the model performs poorly and\n",
    "the weights are not chosen properly. To correct the weights, you need to\n",
    "use an optimizer. The traditional optimizer is called **Gradient**\n",
    "**Descen**t.\n",
    "\n",
    "The gradient descent takes the derivative and decreases or increases the\n",
    "weight. If the derivative is positive, the weight is decreased. If the\n",
    "derivative is negative, the weight increases. The model will update the\n",
    "weights and recompute the error. This process is repeated until the\n",
    "error does not change anymore. Each process is called an **iteration**.\n",
    "Besides, the gradients are multiplied by a learning rate. It indicates\n",
    "the speed of the learning.\n",
    "\n",
    "If the learning rate is too small, it will take very long time for the\n",
    "algorithm to converge (i.e requires lots of iterations). If the learning\n",
    "rate is too high, the algorithm might never converge.\n",
    "\n",
    "<img src=\"image/image60.png\" >\n",
    "\n",
    "You can see from the picture above, the model repeats the process about\n",
    "20 times before to find a stable value for the weights, therefore\n",
    "reaching the lowest error.\n",
    "\n",
    "**Note that**, the error is not equal to zero but stabilizes around 5.\n",
    "It means, the model makes a typical error of 5. If you want to reduce\n",
    "the error, you need to add more information to the model such as more\n",
    "variables or use different estimators.\n",
    "\n",
    "You remember the first equation\n",
    "\n",
    "$$y = \\beta + \\alpha X + \\epsilon$$\n",
    "\n",
    "The final weights are 3.8 and 2.78. The video below shows you how the\n",
    "gradient descent optimize the loss function to find this weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://media.giphy.com/media/WNlzMIObPEFS3rjfX1/giphy.gif\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://media.giphy.com/media/WNlzMIObPEFS3rjfX1/giphy.gif\" frameborder=\"0\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train a Linear Regression with TensorFlow\n",
    "\n",
    "Now that you have a better understanding of what is happening behind the\n",
    "hood, you are ready to use the `estimator` API provided by TensorFlow to\n",
    "train your first linear regression.\n",
    "\n",
    "You will use the Boston Dataset, which includes the following variables\n",
    "\n",
    "| crim    | per capita crime rate by town                                |\n",
    "| ------- | ------------------------------------------------------------ |\n",
    "| zn      | proportion of residential land zoned for lots over 25,000 sq.ft. |\n",
    "| indus   | proportion of non-retail business acres per town.            |\n",
    "| nox     | nitric oxides concentration                                  |\n",
    "| rm      | average number of rooms per dwelling                         |\n",
    "| age     | proportion of owner-occupied units built prior to 1940       |\n",
    "| dis     | weighted distances to five Boston employment centres         |\n",
    "| tax     | full-value property-tax rate per  dollars 10,000             |\n",
    "| ptratio | pupil-teacher ratio by town                                  |\n",
    "| medv    | Median value of owner-occupied homes in thousand dollars     |\n",
    "\n",
    "You will use three different datasets:\n",
    "\n",
    "| dataset    | objective                                            | shape   |\n",
    "| ---------- | ---------------------------------------------------- | ------- |\n",
    "| Training   | Train the model and obtain the weights               | 400, 10 |\n",
    "| Evaluation | Evaluate the performance of the model on unseen data | 100, 10 |\n",
    "| Predict    | Use the model to predict house value on new data     | 6, 10   |\n",
    "\n",
    "The objectives is to use the features of the dataset to predict the\n",
    "value of the house.\n",
    "\n",
    "During the second part of the tutorial, you will learn how to use\n",
    "TensorFlow with three different way to import the data:\n",
    "\n",
    "-   With Pandas\n",
    "\n",
    "-   With Numpy\n",
    "\n",
    "-   Only TF\n",
    "\n",
    "Note that, all options **provide the same results. **\n",
    "\n",
    "You will learn how to use the high-level API to build, train an evaluate\n",
    "a linear regression model. If you were using the low-level API, you had\n",
    "to define by hand the:\n",
    "\n",
    "-   Loss function\n",
    "\n",
    "-   Optimize: Gradient descent\n",
    "\n",
    "-   Matrices multiplication\n",
    "\n",
    "-   Graph and tensor\n",
    "\n",
    "This is tedious and more complicated for beginner.\n",
    "\n",
    "Pandas\n",
    "------\n",
    "\n",
    "You need to import the necessary libraries to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1)** Import the data with panda.\n",
    "\n",
    "You define the column names and store it in `COLUMNS`. You can use\n",
    "`pd.read_csv()` to import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "\n",
    "training_set = pd.read_csv(\"E:/boston_train.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "\n",
    "test_set = pd.read_csv(\"E:/boston_test.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "\n",
    "prediction_set = pd.read_csv(\"E:/boston_predict.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set.shape, test_set.shape, prediction_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the label, i.e. your y, is included in the dataset. So you\n",
    "need to define two other lists. One containing only the features and one\n",
    "with the name of the label only. These two lists will tell your\n",
    "estimator what are the features in the dataset and what column name is\n",
    "the label\n",
    "\n",
    "It is done with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\n",
    "            \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2)** Convert the data\n",
    "\n",
    "You need to convert the numeric variables in the proper format.\n",
    "Tensorflow provides a method to convert continuous variable:\n",
    "`tf.feature_column.numeric_column()`.\n",
    "\n",
    "In the previous step, you define a list a feature you want to include in\n",
    "the model. Now you can use this list to convert them into numeric data.\n",
    "If you want to exclude features in your model, feel free to drop one or\n",
    "more variables in the list FEATURES before you construct the\n",
    "`feature\\_col`.\n",
    "\n",
    "Note that you will use Python list comprehension with the list\n",
    "`FEATURES` to create a new list named `feature_cols`. It helps you\n",
    "avoid writing nine times `tf.feature_column.numeric_column()`. A list\n",
    "comprehension is a faster and cleaner way to create new lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3)** Define the estimator\n",
    "\n",
    "In this step, you need to define the estimator. Tensorflow currently\n",
    "provides 6 pre-built estimators, including 3 for classification task and\n",
    "3 for regression task:\n",
    "\n",
    "-   Regressor\n",
    "    -   DNNRegressor\n",
    "    -   LinearRegressor\n",
    "    -   DNNLineaCombinedRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Classifier\n",
    "    -   DNNClassifier\n",
    "    -   LinearClassifier \n",
    "    -   DNNLineaCombinedClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will use the `Linear Regressor`. To access this\n",
    "function, you need to use `tf.estimator`.\n",
    "\n",
    "The function needs two arguments:\n",
    "\n",
    "-   `feature\\_columns`: Contains the variables to include in the model\n",
    "\n",
    "-   `model\\_dir`: path to store the graph, save the model parameters, etc\n",
    "\n",
    "Tensorflow will automatically create a file named `train` in your\n",
    "working directory. You need to use this path to access the Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_cols,\n",
    "    model_dir=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tricky part with TensorFlow is the way to feed the model. Tensorflow\n",
    "is designed to work with parallel computing and very large dataset. Due\n",
    "to the limitation of the machine resources, it is impossible to feed the\n",
    "model with all the data at once. For that, you need to feed a batch of\n",
    "data each time. Note that, we are talking about huge dataset with\n",
    "millions or more records. If you don’t add batch, you will end up with a\n",
    "memory error.\n",
    "\n",
    "For instance, if your data contains 100 observations and you define a\n",
    "batch size of 10, it means the model will see 10 observations for each\n",
    "iteration (10\\*10).\n",
    "\n",
    "When the model has seen all the data, it finishes one **epoch**. An\n",
    "epoch defines how many times you want the model to see the data. It is\n",
    "better to set this step to `none` and let the model performs iteration\n",
    "$x$ number of time.\n",
    "\n",
    "A second information to add is if you want to shuffle the data before\n",
    "each iteration. During the training, it is important to shuffle the data\n",
    "so that the model does not learn specific pattern of the dataset. If the\n",
    "model learns the details of the underlying pattern of the data, it will\n",
    "have difficulties to generalize the prediction for unseen data. This is\n",
    "called **overfitting**. The model performs well on the training data but\n",
    "cannot predict correctly for unseen data.\n",
    "\n",
    "TensorFlow makes this two steps easy to do. When the data goes to the\n",
    "pipeline, it knows how many observations it needs (batch) and if it has\n",
    "to shuffle the data.\n",
    "\n",
    "To instruct Tensorflow how to feed the model, you can use\n",
    "`pandas_input_fn`. This object needs 5 parameters:\n",
    "\n",
    "-   `x`: feature data\n",
    "\n",
    "-   `y`: label data\n",
    "\n",
    "-   `batch_size`: batch. By default 128\n",
    "\n",
    "-   `num_epoch`: Number of epoch, by default 1\n",
    "\n",
    "-   `shuffle`: Shuffle or not the data. By default, None\n",
    "\n",
    "You need to feed the model many times so you define a function to repeat\n",
    "this process. all this function `get_input_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "       x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "       y = pd.Series(data_set[LABEL].values),\n",
    "       batch_size=n_batch,   \n",
    "       num_epochs=num_epochs,\n",
    "       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual method to evaluate the performance of a model is to:\n",
    "\n",
    "-   Train the model\n",
    "\n",
    "-   Evaluate the model in a different dataset\n",
    "\n",
    "-   Make prediction\n",
    "\n",
    "Tensorflow estimator provides three different functions to carry out\n",
    "this three steps easily.\n",
    "\n",
    "**Step 4)**: Train the model\n",
    "\n",
    "You can use the estimator `train` to evaluate the model. The train\n",
    "estimator needs an `input_fn` and a number of steps. You can use the\n",
    "function you created above to feed the model. Then, you instruct the\n",
    "model to iterate 1000 times. Note that, you don’t specify the number of\n",
    "epochs, you let the model iterates 1000 times. If you set the number of\n",
    "epoch to 1, then the model will iterate 4 times: There are 400 records\n",
    "in the training set, and the batch size is 128\n",
    "\n",
    "1.  128 rows\n",
    "\n",
    "2.  128 rows\n",
    "\n",
    "3.  128 rows\n",
    "\n",
    "4.  16 rows\n",
    "\n",
    "Therefore, it is easier to set the number of epoch to none and define\n",
    "the number of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(input_fn=get_input_fn(training_set, \n",
    "                                      num_epochs=None,\n",
    "                                      n_batch = 128,\n",
    "                                      shuffle=False),\n",
    "                                      steps=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the Tensorboard will the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activate hello-tf\n",
    "# For MacOS\n",
    "tensorboard --logdir=./train\n",
    "# For Windows\n",
    "tensorboard --logdir=train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5)** Evaluate your model\n",
    "\n",
    "You can evaluate the fit of your model on the test set with the code\n",
    "below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = estimator.evaluate(\n",
    "    input_fn=get_input_fn(test_set,\n",
    "                          num_epochs=1,\n",
    "                          n_batch = 128,\n",
    "                          shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the loss with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a loss of 3215. You can check the summary statistic to get\n",
    "an idea of how big the error is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['medv'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary statistic above, you know that the average price for a\n",
    "house is 22 thousand, with a minimum price of 9 thousands and maximum of\n",
    "50 thousand. The model makes a typical error of 3k dollars.\n",
    "\n",
    "**Step 6)** Make the prediction\n",
    "\n",
    "Finally, you can use the estimator `predict` to estimate the value of 6\n",
    "Boston houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = estimator.predict(\n",
    "    input_fn=get_input_fn(prediction_set,\n",
    "                          num_epochs=1,\n",
    "                          n_batch = 128,\n",
    "                          shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the estimated values of $y$, you can use this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model forecast the following values:\n",
    "\n",
    "| House | Prediction |      |\n",
    "| ----- | ---------- | ---- |\n",
    "| 1     | 32.29      |      |\n",
    "| 2     | 18.96      |      |\n",
    "| 3     | 27.27      |      |\n",
    "| 4     | 29.29      |      |\n",
    "| 5     | 16.43      |      |\n",
    "| 7     | 21.46      |      |\n",
    "\n",
    "Note that we don’t know the true value of $y$. In the tutorial of deep\n",
    "learning, you will try to beat the linear model\n",
    "\n",
    "Numpy Solution\n",
    "--------------\n",
    "\n",
    "This section explains how to train the model using a numpy estimator to\n",
    "feed the data. The method is the same exept that you will use\n",
    "`numpy_input_fn` estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_n = pd.read_csv(\"E:/boston_train.csv\").values\n",
    "\n",
    "test_set_n = pd.read_csv(\"E:/boston_test.csv\").values\n",
    "\n",
    "prediction_set_n = pd.read_csv(\"E:/boston_predict.csv\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1)** Import the data\n",
    "\n",
    "First of all, you need to differentiate the feature variables from the\n",
    "label. You need to do this for the training data and evaluation. It is\n",
    "faster to define a function to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df): \n",
    "    X_train = df[:, :-3]\n",
    "    y_train = df[:,-3]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function to split the label from the features of the\n",
    "train/evaluate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(training_set_n)\n",
    "X_test, y_test = prepare_data(test_set_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to exclude the last column of the prediction dataset because it\n",
    "contains only `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = prediction_set_n[:, :-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the shape of the array. Note that, the label should not have a\n",
    "dimension, it means `(400,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, x_predict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct the feature columns as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "      tf.feature_column.numeric_column('x', shape=X_train.shape[1:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator is defined as before, you instruct the feature columns and\n",
    "where to save the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    model_dir=\"train1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the numpy estimapor to feed the data to the model and then\n",
    "train the model. Note that, we define the `input_fn` function before to\n",
    "ease the readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the estimator\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train},\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_epochs=None)\n",
    "\n",
    "estimator.train(input_fn = train_input,steps=5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You replicate the same step with a different estimator to evaluate your\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test},\n",
    "    y=y_test, shuffle=False,\n",
    "    batch_size=128,\n",
    "    num_epochs=1)\n",
    "\n",
    "estimator.evaluate(eval_input,steps=None) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, you can compute the prediction. It should be the similar as\n",
    "pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": x_predict},\n",
    "    batch_size=128,\n",
    "     num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "y = estimator.predict(test_input) \n",
    "\n",
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow solution \n",
    "--------------------\n",
    "\n",
    "The last section is dedicated to a TensorFlow solution. This method is\n",
    "sligthly more complicated than the other one.\n",
    "\n",
    "Note that if you use Jupyter notebook, you need to Restart and clean the\n",
    "kernel to run this session.\n",
    "\n",
    "TensorFlow has built a great tool to pass the data into the pipeline. In\n",
    "this section, you will build the `input_fn` function by yourself.\n",
    "\n",
    "**Step 1)** Define the path and the format of the data\n",
    "\n",
    "First of all, you declare two variables with the path of the csv file.\n",
    "Note that, you have two files, one for the training set and one for the\n",
    "testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "df_train = \"E:/boston_train.csv\"\n",
    "\n",
    "df_eval = \"E:/boston_test.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you need to define the columns you want to use from the csv file.\n",
    "We will use all. After that, you need to declare the type of variable it\n",
    "is.\n",
    "\n",
    "Floats variable are defined by `[0.]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "RECORDS_ALL = [[0.0], [0.0], [0.0], [0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2)** Define the `input_fn` function\n",
    "\n",
    "The function can be broken into three part:\n",
    "\n",
    "1.  Import the data\n",
    "\n",
    "2.  Create the iterator\n",
    "\n",
    "3.  Consume the data\n",
    "\n",
    "Below is the overal code to define the function. The code will be\n",
    "explained after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, batch_size, num_epoch = None):\n",
    "   # Step 1\n",
    "    def parse_csv(value):\n",
    "        columns = tf.decode_csv(value, record_defaults= RECORDS_ALL)\n",
    "        features = dict(zip(COLUMNS, columns))\n",
    "        #labels = features.pop('median_house_value')\n",
    "        labels =  features.pop('medv')\n",
    "        return features, labels\n",
    "    \n",
    "      # Extract lines from input files using the Dataset API.\n",
    "    dataset = (tf.data.TextLineDataset(data_file) # Read text file\n",
    "       .skip(1) # Skip header row\n",
    "       .map(parse_csv))\n",
    "    \n",
    "    dataset = dataset.repeat(num_epoch)\n",
    "    dataset = dataset.batch(batch_size) \n",
    "    # Step 3\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the data**\n",
    "\n",
    "For a csv file, the dataset method reads one line at a time. To build\n",
    "the dataset, you need to use the object `TextLineDataset.` Your dataset\n",
    "has a header so you need to use `skip(1)` to skip the first line. At\n",
    "this point, you only read the data and exclude the header in the\n",
    "pipeline. To feed the model, you need to separate the features from the\n",
    "label. The method used to apply any transformation to the data is map.\n",
    "\n",
    "This method calls a function that you will create in order to instruct\n",
    "how to transform the data.\\\n",
    "In a nutshell, you need to pass the data in the TextLineDataset object,\n",
    "exclude the header and apply a transformation which is instructed by a\n",
    "function.\\\n",
    "Code explanation\n",
    "\n",
    "-   `tf.data.TextLineDataset(data_file)`: This line read the csv file\n",
    "\n",
    "-   `.skip(1)` : skip the header\n",
    "\n",
    "-   `.map(parse_csv))`: parse the records into the tensors\\\n",
    "    You need to define a function to instruct the map object. You can\n",
    "    call this function parse\\_csv.\n",
    "\n",
    "This function parses the csv file with the method tf.decode\\_csv and\n",
    "declares the features and the label. The features can be declared as a\n",
    "dictionary or a tuple. You use the dictionary method because it is more\n",
    "convenient.\n",
    "Code explanation\n",
    "\n",
    "-   `tf.decode_csv(value, record_defaults= RECORDS_ALL)`: the method\n",
    "    decode\\_csv uses the output of the TextLineDataset to read the csv\n",
    "    file. record\\_defaults instructs TensorFlow about the columns type.\n",
    "\n",
    "-   `dict(zip(_CSV_COLUMNS, columns))`: Populate the dictionary with all\n",
    "    the columns extracted during this data processing\n",
    "\n",
    "-   `features.pop('median_house_value')`: Exclude the target variable\n",
    "    from the feature variable and create a label variable\n",
    "\n",
    "The Dataset needs further elements to iteratively feeds the Tensors.\n",
    "Indeed, you need to add the method repeat to allow the dataset to\n",
    "continue indefinitely to feed the model. If you don’t add the method,\n",
    "the model will iterate only one time and then throw an error because no\n",
    "more data are fed in the pipeline.\n",
    "\n",
    "After that, you can control the batch size with the batch method. It\n",
    "means you tell the dataset how many data you want to pass in the\n",
    "pipeline for each iteration. If you set a big batch size, the model will\n",
    "be slow.\n",
    "\n",
    "**Step 3) Create the iterator**\n",
    "\n",
    "Now you are ready for the second step: create an iterator to return the\n",
    "elements in the dataset.\n",
    "\n",
    "The simplest way of creating an operator is with the method\n",
    "`make_one_shot_iterator`.\n",
    "\n",
    "After that, you can create the features and labels from the iterator.\n",
    "\n",
    "**Step 4) Consume the data**\n",
    "\n",
    "You can check what happens with `input_fn` function. You need to call\n",
    "the function in a session to consume the data. You try with a batch size\n",
    "equals to 1.\n",
    "\n",
    "Note that, it prints the features in a dictionary and the label as an\n",
    "array.\n",
    "\n",
    "It will show the first line of the csv file. You can try to run this\n",
    "code many times with different batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_batch = input_fn(df_train, batch_size = 1, num_epoch = None)\n",
    "with tf.Session() as sess:\n",
    "    first_batch  = sess.run(next_batch)\n",
    "    print(first_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4)** Define the feature column\n",
    "\n",
    "You need to define the numeric columns as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1= tf.feature_column.numeric_column('crim')\n",
    "X2= tf.feature_column.numeric_column('zn')\n",
    "X3= tf.feature_column.numeric_column('indus')\n",
    "X4= tf.feature_column.numeric_column('nox')\n",
    "X5= tf.feature_column.numeric_column('rm')\n",
    "X6= tf.feature_column.numeric_column('age')\n",
    "X7= tf.feature_column.numeric_column('dis')\n",
    "X8= tf.feature_column.numeric_column('tax')\n",
    "X9= tf.feature_column.numeric_column('ptratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you need to combined all the variables in a *bucket*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = [X1, X2, X3,X4, X5, X6,X7, X8, X9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5)** Build the model\n",
    "\n",
    "You can train the model with the estimator `LinearRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.estimator.LinearRegressor(feature_columns=base_columns,\n",
    "                                         model_dir='train3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to use a `lambda` function to allow to write the argument in\n",
    "the function `inpu_fn`. If you don’t use a `lambda` function, you cannot\n",
    "train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the estimator\n",
    "model.train(steps =1000,\n",
    "    input_fn=lambda : input_fn(df_train,batch_size=128, num_epoch = None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can evaluate the fit of you model on the test set with the code\n",
    "below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(steps =None,input_fn=lambda: input_fn(df_eval, batch_size =128, num_epoch = 1))\n",
    "for key in results:\n",
    "   print(\"   {}, was: {}\".format(key, results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is predicting the value of $y$ based on the value of $X$,\n",
    "the matrices of the features. You can write a dictionary with the values\n",
    "you want to predict. Your model has 9 features so you need to provide a\n",
    "value for each. The model will provide a prediction for each of them.\n",
    "\n",
    "In the code below, you wrote the values of each features that is\n",
    "contained in the `df_predict` csv file.\n",
    "\n",
    "You need to write a new `input_fn` function because there is no label in\n",
    "the dataset. You can use the API `from_tensor` from the `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input = {\n",
    "    'crim': [0.03359,5.09017,0.12650,0.05515,8.15174,0.24522],\n",
    "    'zn': [75.0,0.0,25.0,33.0,0.0,0.0],\n",
    "    'indus': [2.95,18.10,5.13,2.18,18.10,9.90],\n",
    "    'nox': [0.428,0.713,0.453,0.472,0.700,0.544],\n",
    "    'rm': [7.024,6.297,6.762,7.236,5.390,5.782],\n",
    "    'age': [15.8,91.8,43.4,41.1,98.9,71.7],\n",
    "    'dis': [5.4011,2.3682,7.9809,4.0220,1.7281,4.0317],\n",
    "    'tax': [252,666,284,222,666,304],\n",
    "    'ptratio': [18.3,20.2,19.7,18.4,20.2,18.4]\n",
    "}\n",
    "\n",
    "def test_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensors(prediction_input)\n",
    "    return dataset\n",
    "\n",
    "# Predict all our prediction_input\n",
    "pred_results = model.predict(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finaly, you print the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in enumerate(pred_results):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To train a model, you need to:\n",
    "\n",
    "-   Define the features: Independent variables: X\n",
    "\n",
    "-   Define the label: Dependent variable: y\n",
    "\n",
    "-   Construct a train/test set\n",
    "\n",
    "-   Define the initial weight\n",
    "\n",
    "-   Define the loss function: MSE\n",
    "\n",
    "-   Optimize the model: Gradient descent\n",
    "\n",
    "-   Define:\n",
    "    -   Learning rate\n",
    "    -   Number of epoch \n",
    "    -   Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you learned how to use the high level API for a linear\n",
    "regression estimator. You need to define:\n",
    "\n",
    "1.  Feature columns. If continuous:\n",
    "    `tf.feature_column.numeric_column()`. You can populate a list with\n",
    "    python list comprehension\n",
    "2.  The estimator: `tf.estimator.LinearRegressor(feature\\_columns,\n",
    "    model\\_dir)`\n",
    "3.  A function to import the data, the batch size and epoch: `input_fn()`\n",
    "\n",
    "After that, you are ready to train, evaluate and make prediction with\n",
    "`train()`, `evaluate()` and `predict()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
